name: Tests and Quality Checks

on:
  push:
    branches: [main, develop, "001-*"]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

jobs:
  test:
    name: Test Python ${{ matrix.python-version }}
    runs-on: ${{ matrix.os }}

    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest]
        python-version: ["3.11", "3.12"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          uv pip install --system -e ".[dev]"

      - name: Run linting (ruff)
        run: |
          ruff check src/ tests/

      - name: Run formatting check (black)
        run: |
          black --check src/ tests/

      - name: Run type checking (mypy)
        run: |
          mypy src/
        continue-on-error: true  # Don't fail on type errors initially

      - name: Run tests with coverage
        run: |
          pytest tests/ \
            --benchmark-skip \
            --cov=src \
            --cov-report=xml \
            --cov-report=term \
            -v

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

  security:
    name: Security Audit
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          uv pip install --system -e ".[dev]"
          uv pip install --system bandit[toml]

      - name: Run security checks (bandit)
        run: |
          bandit -r src/ -f json -o bandit-report.json
        continue-on-error: true

      - name: Upload security report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-security-report
          path: bandit-report.json

  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for comparison

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          uv pip install --system -e ".[dev]"

      - name: Download baseline benchmarks
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results
          path: .benchmarks/
        continue-on-error: true

      - name: Run performance tests
        run: |
          pytest tests/performance/ \
            --benchmark-only \
            --benchmark-autosave \
            --benchmark-save-data \
            --benchmark-json=benchmark_results.json
        continue-on-error: true  # Don't fail on benchmark issues

      - name: Store benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            .benchmarks/
            benchmark_results.json

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            try {
              const results = JSON.parse(fs.readFileSync('benchmark_results.json', 'utf8'));
              const comment = `## ðŸ“Š Performance Benchmark Results

              Benchmark tests completed. See artifacts for detailed results.

              **Note**: Detailed performance analysis available in workflow artifacts.`;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } catch (error) {
              console.log('Could not post benchmark results:', error.message);
            }
